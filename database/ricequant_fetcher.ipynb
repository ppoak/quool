{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.last_date', 'r') as f:\n",
    "    start = (pd.to_datetime(f.read()) + pd.Timedelta(days=1)).strftime(r'%Y%m%d')\n",
    "stop = datetime.datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "all_stock = all_instruments(type='CS', market='cn')\n",
    "all_stock = all_stock.order_book_id.to_list()\n",
    "comprehesive_index = [\n",
    "    '000905.XSHG', '000016.XSHG', '000001.XSHG', '000300.XSHG', \n",
    "    '000009.XSHG', '000010.XSHG', '399012.XSHE', '399106.XSHE', \n",
    "    '399001.XSHE', '399300.XSHE', '399102.XSHE', '000985.XSHG',\n",
    "    '399101.XSHE', \n",
    "]\n",
    "citics_index = [f'CI005{str(i).zfill(3)}.INDX' for i in range(1, 31)]\n",
    "trade_dates = get_trading_dates(start_date=start, end_date=today)\n",
    "trade_dates = pd.DataFrame(pd.to_datetime(trade_dates), columns=['trade_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for index in tqdm(comprehesive_index):\n",
    "    w = index_weights(index, start_date=start, end_date=stop)\n",
    "    w = w.sort_index()\n",
    "    w.columns = [index]\n",
    "    weights.append(w)\n",
    "weights = pd.concat(weights, axis=1).swaplevel().sort_index()\n",
    "weights.to_parquet(f'index-weights_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Instruments Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = all_instruments()\n",
    "instruments.listed_date = pd.to_datetime(instruments.listed_date, errors='coerce')\n",
    "instruments.de_listed_date = pd.to_datetime(instruments.de_listed_date, errors='coerce')\n",
    "instruments = instruments.set_index('order_book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments.to_parquet('instruments-info.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_data(code, start, stop, frequency='1d'):\n",
    "    data = get_price(\n",
    "        order_book_ids=code, \n",
    "        start_date=start, \n",
    "        end_date=stop, \n",
    "        adjust_type='none',\n",
    "        frequency=frequency,\n",
    "    )\n",
    "    if data is None:\n",
    "        return None\n",
    "    \n",
    "    if frequency == '1m':\n",
    "        data = data.rename({\"amount\": \"total_turnover\"}, axis=1).drop('num_trades', axis=1)\n",
    "        return data.astype('float32')\n",
    "    \n",
    "    post_close = get_price(\n",
    "        order_book_ids=code, \n",
    "        start_date=start, \n",
    "        end_date=stop, \n",
    "        fields=['close'], \n",
    "        adjust_type='post',\n",
    "    )['close']\n",
    "    data['adjfactor'] = post_close / data['close']\n",
    "    data = data.rename({\"total_turnover\": \"amount\"}, axis=1)\n",
    "    data = pd.concat([\n",
    "        data, get_shares(code, start_date=start, end_date=stop)\n",
    "    ], axis=1, join='inner').rename(columns={\"total\": \"total_shares\"})\n",
    "    data = pd.concat([\n",
    "        data, get_turnover_rate(\n",
    "            order_book_ids=code, \n",
    "            start_date=start, \n",
    "            end_date=stop, \n",
    "            fields='today'\n",
    "    )], axis=1, join='inner').rename(columns={\"today\": \"turnover\"})\n",
    "    \n",
    "    # process suspended and st information\n",
    "    suspended = is_suspended(order_book_ids=code, start_date=start, end_date=stop).stack().swaplevel()\n",
    "    suspended.name = 'suspended'\n",
    "    st = is_st_stock(order_book_ids=code, start_date=start, end_date=stop).stack().swaplevel()\n",
    "    st.name = 'st'\n",
    "    data = pd.concat([data, st, suspended], axis=1, join='inner')\n",
    "    \n",
    "    types = set(data.columns.to_list()) - {\"st\", \"suspended\"}\n",
    "    types = {col: \"float32\" for col in types}\n",
    "    types[\"st\"] = \"bool\"\n",
    "    types[\"suspended\"] = \"bool\"\n",
    "    data.index.names = ['order_book_id', 'date']\n",
    "    return data.astype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for stock in tqdm(all_stock + comprehesive_index):\n",
    "#     data.append(get_data(stock, start, stop))\n",
    "# pd.concat(data).to_parquet(f'quotes-day_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_data(all_stock, start, stop).to_parquet(f'quotes-day_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price(comprehesive_index, start, stop).to_parquet(f'index-quotes-day_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_data(all_stock, start, stop, '1m').to_parquet(f\"quotes-min_{start}-{stop}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_data(comprehesive_index, start, stop, '1m').to_parquet(f\"index-quotes-min_{start}-{stop}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ms = pd.date_range(start, stop, freq='MS')\n",
    "# me = pd.date_range(start, stop, freq='M')\n",
    "# for i, (s, e) in tqdm(enumerate(zip(ms, me))):\n",
    "#     price_data = get_price(order_book_ids=all_stock + comprehesive_index, start_date=s, \n",
    "#               end_date=e, frequency='1m', adjust_type='none').drop('num_trades', axis=1)\n",
    "#     price_data['adjfactor'] =  get_price(order_book_ids=all_stock + comprehesive_index, start_date=s, \n",
    "#               end_date=e, frequency='1m', fields='close', adjust_type='post')['close'] / price_data['close']\n",
    "#     price_data = price_data.astype('float32')\n",
    "#     price_data.to_parquet(f'{s.strftime(\"%Y%m\")}.parquet')\n",
    "#     del price_data\n",
    "#     gc.collect()\n",
    "#     if (i + 1) % 12 == 0:\n",
    "#         subprocess.run(['tar', '-cvzf', f'{e.year}.tar.gz'] + [f'{e.year}{str(mon).zfill(2)}.parquet' for mon in range(1, 13)])\n",
    "#         subprocess.run(['rm', '-rf'] + [f'{e.year}{str(mon).zfill(2)}.parquet' for mon in range(1, 13)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(x: pd.DataFrame, keep_first=False):\n",
    "    res = x.diff()\n",
    "    if keep_first:\n",
    "        res.iloc[0] = x.iloc[0]\n",
    "    return res\n",
    "\n",
    "def get_financial_data(code, start, stop, keep_first=False):\n",
    "    day_before_start = trading_date_offset(start, -1)\n",
    "    df = get_factor(order_book_ids=code, factor=all_field, start_date=day_before_start, end_date=stop)\n",
    "    idx = df.groupby(level=0).apply(lambda x: diff(x, keep_first)).replace(0, np.nan).dropna(axis=0, how='all').index\n",
    "    df = df.loc[idx]\n",
    "    df.columns = df.columns.str.slice(0, -6)\n",
    "    return df.sort_index().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = pd.read_html(\"https://www.ricequant.com/doc/rqdata/python/fundamentals-dictionary.html#%E5%9F%BA%E7%A1%80%E8%B4%A2%E5%8A%A1%E6%95%B0%E6%8D%AE\")\n",
    "income_sheet_field = fields[3][\"字段\"]\n",
    "balance_sheet_field = fields[4][\"字段\"]\n",
    "cashflow_sheet_field = fields[5][\"字段\"]\n",
    "all_field = (income_sheet_field + \"_ttm_0\").to_list() + \\\n",
    "            (balance_sheet_field + \"_ttm_0\").to_list() + \\\n",
    "            (cashflow_sheet_field + \"_ttm_0\").to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# data = Parallel(n_jobs=-1, backend='loky')(delayed(get_financial_data)\n",
    "#     (code, \"20000105\", \"20231231\", True) for code in tqdm(all_stock)\n",
    "# )\n",
    "# pd.concat(data).to_parquet(f'financial_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_data = get_financial_data(all_stock, start, stop)\n",
    "if financial_data is not None:\n",
    "    financial_data.to_parquet(f'financial_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_mapping = []\n",
    "for date in tqdm(trade_dates.trade_date):\n",
    "    mapping = get_instrument_industry(order_book_ids=all_stock, date=date, source='citics_2019', level=0)\n",
    "    if mapping is not None:\n",
    "        mapping.index = pd.MultiIndex.from_arrays([[date] * len(mapping), mapping.index], names=['date', mapping.index.name])\n",
    "        mapping['source'] = 'citics'\n",
    "        industry_mapping.append(mapping)\n",
    "industry_mapping = pd.concat(industry_mapping).swaplevel().sort_index()\n",
    "industry_mapping.to_parquet(f'industry-info_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividend and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_split(code, start, stop):\n",
    "    if isinstance(code, str):\n",
    "        code = [code]\n",
    "    \n",
    "    # processing declare, dividend and split information\n",
    "    divinfo = get_dividend(code, start_date=start, end_date=stop, market='cn')\n",
    "    if divinfo is not None:\n",
    "        divinfo = divinfo.reset_index().set_index(['order_book_id', 'ex_dividend_date']).drop(\n",
    "            ['advance_date', 'quarter', 'payable_date', 'book_closure_date', 'declaration_announcement_date']\n",
    "        , axis=1)\n",
    "        divinfo[\"dividend_factor\"] = divinfo['dividend_cash_before_tax'] / divinfo[\"round_lot\"]\n",
    "        divinfo = divinfo.drop(['dividend_cash_before_tax', 'round_lot'], axis=1)\n",
    "        divinfo = pd.DataFrame(divinfo.groupby(level=divinfo.index.names).sum().values,\n",
    "                index=divinfo.index[~divinfo.index.duplicated(keep='first')], columns=[\"divfactor\"])\n",
    "    else:\n",
    "        divinfo = None\n",
    "\n",
    "    splitinfo = get_split(all_stock, start_date=start, end_date=stop, market='cn')\n",
    "    if splitinfo is not None:\n",
    "        splitinfo['splitfactor'] = splitinfo['split_coefficient_to'] / splitinfo['split_coefficient_from'] - 1\n",
    "        splitinfo = splitinfo.drop(['split_coefficient_to', 'split_coefficient_from', 'cum_factor', 'book_closure_date', 'payable_date'], axis=1)\n",
    "        splitinfo = splitinfo.loc[~splitinfo.index.duplicated(keep='first')]\n",
    "    else:\n",
    "        splitinfo = None\n",
    "    \n",
    "    if not (splitinfo is None and divinfo is None):\n",
    "        spdiv = pd.concat([splitinfo, divinfo], axis=1)\n",
    "        spdiv.index.names = ['order_book_id', 'date']\n",
    "        return spdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dividend_split(all_stock, start, stop)\n",
    "if df is not None:\n",
    "    df.to_parquet(f'dividend-split_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for stock in tqdm(all_stock):\n",
    "#     df = get_securities_margin(stock, start_date=start, end_date=stop)\n",
    "#     if df is not None:\n",
    "#         data.append(df.astype('float32'))\n",
    "# pd.concat(data).to_parquet(f'security-margin_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_securities_margin(all_stock, start_date=start, end_date=stop)\n",
    "if df is not None:\n",
    "    df.to_parquet(f'security-margin_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for stock in tqdm(all_stock):\n",
    "#     df = get_stock_connect(stock, start_date=start, end_date=stop)\n",
    "#     if df is not None:\n",
    "#         data.append(df.astype('float32'))\n",
    "# pd.concat(data).to_parquet(f'stock-connect_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_stock_connect(all_stock, start_date=start, end_date=stop)\n",
    "if df is not None:\n",
    "    df.index.names = [\"order_book_id\", \"date\"]\n",
    "    df.to_parquet(f'stock-connect_{start}-{stop}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "data_files = list(Path('.').glob('*.parquet'))\n",
    "subprocess.run([\"tar\", \"-czvf\", f\"data_{start}-{stop}.tar.gz\",] + data_files)\n",
    "for file in data_files:\n",
    "    file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if datetime.datetime.today().strftime(\"%H%M\") < \"1500\":\n",
    "#     stop = (pd.to_datetime(stop) - pd.Timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "with open('.last_date', 'w') as f:\n",
    "    f.write(stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b061070c2a4f0a17beb221bbb485cf11738fa39836b1ba79e3ea50588350e39e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
